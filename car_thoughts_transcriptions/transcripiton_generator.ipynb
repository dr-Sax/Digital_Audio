{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deepgram.com/learn/best-python-audio-libraries-for-speech-recognition-in-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path, mkdir, listdir\n",
    "from pydub import AudioSegment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MacOS Path\n",
    "base_path = '/Users/nicolasromano/Documents/Documents - Nicolas’s MacBook Pro/code/AlgoRhythms/Digital_Audio/sound_files/car_thoughts/sept17/'\n",
    "audio_title = 'electronic_music_as_a_model_for_visual_art.m4a'\n",
    "m4a_file = base_path + audio_title\n",
    "GOOGLE_CLOUD_SPEECH_CREDENTIALS = '/Users/nicolasromano/Documents/Documents - Nicolas’s MacBook Pro/code/AlgoRhythms/Digital_Audio/car_thoughts_transcriptions/serene-coyote-346200-4ce0fdf7b3b7.json'\n",
    "\n",
    "wav_file = AudioSegment.from_file(m4a_file, format='m4a')\n",
    "wav_path = f'{m4a_file[0:-3]}wav'\n",
    "file_handle = wav_file.export(wav_path, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_duration_secs = int(len(wav_file) / 1000)\n",
    "file_duration_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mkdir(base_path + 'minute_clips') # folder to store 1 min MAX segmented clips\n",
    "except FileExistsError:\n",
    "    pass # path already made\n",
    "start = 0\n",
    "end = 60\n",
    "\n",
    "while end <= file_duration_secs:\n",
    "    t1 = start\n",
    "    t2 = end # first 2 mins\n",
    "\n",
    "    t1 = t1 * 1000 #Works in milliseconds\n",
    "    t2 = t2 * 1000\n",
    "    newAudio = AudioSegment.from_wav(wav_path)\n",
    "    newAudio = newAudio[t1:t2]\n",
    "\n",
    "    newAudio.export(f'{base_path}/minute_clips/{int(end / 60) - 1}.wav', format=\"wav\") #Exports to a wav file in the current path.\n",
    "\n",
    "    start += 60\n",
    "    end += 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = []\n",
    "for i in range(0, len(listdir(f'{base_path}/minute_clips'))):\n",
    "    audio_files.append(f'{base_path}/minute_clips/{i}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/nicolasromano/Documents/Documents - Nicolas’s MacBook Pro/code/AlgoRhythms/Digital_Audio/sound_files/car_thoughts/sept17//minute_clips/14.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m file1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(transcription_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# append mode\u001b[39;00m\n\u001b[1;32m     18\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m---> 19\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# read the entire audio file\u001b[39;00m\n\u001b[1;32m     22\u001b[0m txt_read \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecognize_google_cloud(audio, credentials_json\u001b[38;5;241m=\u001b[39mGOOGLE_CLOUD_SPEECH_CREDENTIALS)\n",
      "File \u001b[0;32m~/Documents/Documents - Nicolas’s MacBook Pro/code/AlgoRhythms/Digital_Audio/.venv/lib/python3.11/site-packages/speech_recognition/__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mThis audio source is already inside a context manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# attempt to read the file as WAV\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_reader \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename_or_fileobject, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlittle_endian \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m (wave\u001b[39m.\u001b[39mError, \u001b[39mEOFError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/wave.py:630\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    628\u001b[0m         mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    629\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 630\u001b[0m     \u001b[39mreturn\u001b[39;00m Wave_read(f)\n\u001b[1;32m    631\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    632\u001b[0m     \u001b[39mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/wave.py:280\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i_opened_the_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 280\u001b[0m     f \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(f, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    281\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i_opened_the_file \u001b[39m=\u001b[39m f\n\u001b[1;32m    282\u001b[0m \u001b[39m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nicolasromano/Documents/Documents - Nicolas’s MacBook Pro/code/AlgoRhythms/Digital_Audio/sound_files/car_thoughts/sept17//minute_clips/14.wav'"
     ]
    }
   ],
   "source": [
    "first_file = True\n",
    "for path in audio_files[15:]:\n",
    "    if first_file:\n",
    "        transcription_filename = f\"{audio_title[:-4]}.txt\"\n",
    "        transcription = open(transcription_filename, \"w\")\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(path) as source:\n",
    "            audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "        txt_read = r.recognize_google_cloud(audio, credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS)\n",
    "\n",
    "        transcription.writelines(txt_read)\n",
    "        transcription.close()\n",
    "        first_file = False\n",
    "\n",
    "    else:\n",
    "        file1 = open(transcription_filename, \"a\")  # append mode\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(path) as source:\n",
    "            audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "        txt_read = r.recognize_google_cloud(audio, credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS)\n",
    "\n",
    "        file1.write('\\n' + txt_read)\n",
    "        file1.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57c929fe03e723d2be6a7be66a00867cc38dc9903df83aaff55b2ebab5f7f025"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
